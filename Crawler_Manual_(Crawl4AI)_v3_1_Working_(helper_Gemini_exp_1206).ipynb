{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmZ9sBs2H9AOWTG/RLr4Uz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tm-ty/colab-notebooks-tm/blob/main/Crawler_Manual_(Crawl4AI)_v3_1_Working_(helper_Gemini_exp_1206).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# v1"
      ],
      "metadata": {
        "id": "NjXU3bXpLlTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## passo 1"
      ],
      "metadata": {
        "id": "AlGVmezfLqS9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDDMioOuLb-O",
        "outputId": "51afe8a1-f135-4efb-b809-f9417efeed9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crawl4ai in /usr/local/lib/python3.10/dist-packages (0.4.247)\n",
            "Requirement already satisfied: aiosqlite~=0.20 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.20.0)\n",
            "Requirement already satisfied: lxml~=5.3 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (5.3.0)\n",
            "Requirement already satisfied: litellm>=1.53.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.58.1)\n",
            "Requirement already satisfied: numpy<3,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.26.4)\n",
            "Requirement already satisfied: pillow~=10.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (10.4.0)\n",
            "Requirement already satisfied: playwright>=1.49.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.49.1)\n",
            "Requirement already satisfied: python-dotenv~=1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.0.1)\n",
            "Requirement already satisfied: requests~=2.26 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4~=4.12 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (4.12.3)\n",
            "Requirement already satisfied: tf-playwright-stealth>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.1.0)\n",
            "Requirement already satisfied: xxhash~=3.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.5.0)\n",
            "Requirement already satisfied: rank-bm25~=0.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.2.2)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (24.1.0)\n",
            "Requirement already satisfied: colorama~=0.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.4.6)\n",
            "Requirement already satisfied: snowballstemmer~=2.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.2.0)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.10.3)\n",
            "Requirement already satisfied: pyOpenSSL>=24.3.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (25.0.0)\n",
            "Requirement already satisfied: psutil>=6.1.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (6.1.1)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.9.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiosqlite~=0.20->crawl4ai) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.12->crawl4ai) (2.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.11.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.1.7)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.27.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.55.3 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (1.57.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.21.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (4.67.1)\n",
            "Requirement already satisfied: greenlet==3.1.1 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (3.1.1)\n",
            "Requirement already satisfied: pyee==12.0.0 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (12.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (2.27.1)\n",
            "Requirement already satisfied: cryptography<45,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL>=24.3.0->crawl4ai) (43.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2024.12.14)\n",
            "Requirement already satisfied: fake-http-header<0.4.0,>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.3.5)\n",
            "Requirement already satisfied: pytest-mockito<0.0.5,>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.22.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (0.8.2)\n",
            "Requirement already satisfied: pytest>=3 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (8.3.4)\n",
            "Requirement already satisfied: mockito>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.18.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm>=1.53.1->crawl4ai) (0.27.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (6.0.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U crawl4ai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!crawl4ai-setup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0BnBvpuLenM",
        "outputId": "6f8127d2-9793-427e-97e4-b74d10ae67cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m[INIT].... → Running post-installation setup...\u001b[0m\n",
            "\u001b[36m[INIT].... → Installing Playwright browsers...\u001b[0m\n",
            "Installing dependencies...\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "\u001b[32m[COMPLETE] ● Playwright installation completed successfully.\u001b[0m\n",
            "\u001b[36m[INIT].... → Starting database initialization...\u001b[0m\n",
            "\u001b[32m[COMPLETE] ● Database initialization completed successfully.\u001b[0m\n",
            "\u001b[32m[COMPLETE] ● Post-installation setup completed!\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!crawl4ai-doctor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtZP0dcJLf5u",
        "outputId": "725b99b6-f9ba-4acc-dbdb-86881faf4907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m[INIT].... → Running Crawl4AI health check...\u001b[0m\n",
            "\u001b[36m[INIT].... → Crawl4AI 0.4.247\u001b[0m\n",
            "\u001b[36m[TEST].... ℹ Testing crawling capabilities...\u001b[0m\n",
            "\u001b[36m[EXPORT].. ℹ Exporting PDF and taking screenshot took 2.00s\u001b[0m\n",
            "\u001b[32m[FETCH]... ↓ https://crawl4ai.com... | Status: \u001b[32mTrue\u001b[0m | Time: 3.97s\u001b[0m\n",
            "\u001b[36m[SCRAPE].. ◆ Processed https://crawl4ai.com... | Time: 70ms\u001b[0m\n",
            "\u001b[32m[COMPLETE] ● https://crawl4ai.com... | Status: \u001b[32mTrue\u001b[0m | Total: \u001b[33m4.04s\u001b[0m\u001b[0m\n",
            "\u001b[32m[COMPLETE] ● ✅ Crawling test passed!\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m playwright install --with-deps chromium"
      ],
      "metadata": {
        "id": "gYQDslcWLffA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 2: Adaptar o código"
      ],
      "metadata": {
        "id": "oR-iAi_ZLwh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OBS.: As duas linhas baixo não são necessárias no Colab\n",
        "# parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
        "# sys.path.append(parent_dir)"
      ],
      "metadata": {
        "id": "6oDFYo8eLfwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passo 3: Implantar a solução"
      ],
      "metadata": {
        "id": "2v-0qeFeMt3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In_7xZrwMvlY",
        "outputId": "43e19c1e-386b-40d6-a3d3-6b38e32b0773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 4: Monitorar e obter resultados"
      ],
      "metadata": {
        "id": "vLpHPaQ_NNT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependências\n",
        "!pip install -U crawl4ai\n",
        "!crawl4ai-setup\n",
        "!crawl4ai-doctor\n",
        "!python -m playwright install --with-deps chromium\n",
        "\n",
        "# Importar bibliotecas\n",
        "import asyncio\n",
        "from typing import List\n",
        "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "\n",
        "# Função para rastreamento sequencial\n",
        "async def crawl_sequential(urls: List[str]):\n",
        "    print(\"\\n=== Sequential Crawling with Session Reuse ===\")\n",
        "\n",
        "    browser_config = BrowserConfig(\n",
        "        headless=True,\n",
        "        # For better performance in Docker or low-memory environments:\n",
        "        extra_args=[\"--disable-gpu\", \"--disable-dev-shm-usage\", \"--no-sandbox\"],\n",
        "    )\n",
        "\n",
        "    crawl_config = CrawlerRunConfig(\n",
        "        markdown_generator=DefaultMarkdownGenerator()\n",
        "    )\n",
        "\n",
        "    # Criar o crawler (abre o navegador)\n",
        "    crawler = AsyncWebCrawler(config=browser_config)\n",
        "    await crawler.start()\n",
        "\n",
        "    try:\n",
        "        session_id = \"session1\"  # Reutilizar a mesma sessão em todas as URLs\n",
        "        for url in urls:\n",
        "            result = await crawler.arun(\n",
        "                url=url,\n",
        "                config=crawl_config,\n",
        "                session_id=session_id\n",
        "            )\n",
        "            if result.success:\n",
        "                print(f\"Successfully crawled: {url}\")\n",
        "                # Exemplo: verificar o tamanho do markdown\n",
        "                print(f\"Markdown length: {len(result.markdown_v2.raw_markdown)}\")\n",
        "            else:\n",
        "                print(f\"Failed: {url} - Error: {result.error_message}\")\n",
        "    finally:\n",
        "        # Depois que todas as URLs forem concluídas, fechar o crawler (e o navegador)\n",
        "        await crawler.close()\n",
        "\n",
        "# Função principal\n",
        "async def main():\n",
        "    urls = [\n",
        "        \"https://ai.pydantic.dev/agents/\",\n",
        "        \"https://ai.pydantic.dev/models/\",\n",
        "        \"https://ai.pydantic.dev/dependencies/\",\n",
        "        \"https://ai.pydantic.dev/tools/\"\n",
        "    ]\n",
        "    await crawl_sequential(urls)\n",
        "\n",
        "# Executar a função principal\n",
        "#asyncio.run(main()) # <-- LINHA que possívelmente deu erro\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmjYtDBjMxT-",
        "outputId": "3269be87-c614-47bf-f0b8-83f17be97d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crawl4ai in /usr/local/lib/python3.10/dist-packages (0.4.247)\n",
            "Requirement already satisfied: aiosqlite~=0.20 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.20.0)\n",
            "Requirement already satisfied: lxml~=5.3 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (5.3.0)\n",
            "Requirement already satisfied: litellm>=1.53.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.58.1)\n",
            "Requirement already satisfied: numpy<3,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.26.4)\n",
            "Requirement already satisfied: pillow~=10.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (10.4.0)\n",
            "Requirement already satisfied: playwright>=1.49.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.49.1)\n",
            "Requirement already satisfied: python-dotenv~=1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.0.1)\n",
            "Requirement already satisfied: requests~=2.26 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4~=4.12 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (4.12.3)\n",
            "Requirement already satisfied: tf-playwright-stealth>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.1.0)\n",
            "Requirement already satisfied: xxhash~=3.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.5.0)\n",
            "Requirement already satisfied: rank-bm25~=0.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.2.2)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (24.1.0)\n",
            "Requirement already satisfied: colorama~=0.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.4.6)\n",
            "Requirement already satisfied: snowballstemmer~=2.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.2.0)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.10.3)\n",
            "Requirement already satisfied: pyOpenSSL>=24.3.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (25.0.0)\n",
            "Requirement already satisfied: psutil>=6.1.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (6.1.1)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.9.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiosqlite~=0.20->crawl4ai) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.12->crawl4ai) (2.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.11.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.1.7)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.27.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.55.3 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (1.57.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.21.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (4.67.1)\n",
            "Requirement already satisfied: greenlet==3.1.1 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (3.1.1)\n",
            "Requirement already satisfied: pyee==12.0.0 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (12.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (2.27.1)\n",
            "Requirement already satisfied: cryptography<45,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL>=24.3.0->crawl4ai) (43.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2024.12.14)\n",
            "Requirement already satisfied: fake-http-header<0.4.0,>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.3.5)\n",
            "Requirement already satisfied: pytest-mockito<0.0.5,>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.22.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (0.8.2)\n",
            "Requirement already satisfied: pytest>=3 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (8.3.4)\n",
            "Requirement already satisfied: mockito>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.18.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm>=1.53.1->crawl4ai) (0.27.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (6.0.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.2.1)\n",
            "[INIT].... → Running post-installation setup...\n",
            "[INIT].... → Installing Playwright browsers...\n",
            "Installing dependencies...\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "[COMPLETE] ● Playwright installation completed successfully.\n",
            "[INIT].... → Starting database initialization...\n",
            "[COMPLETE] ● Database initialization completed successfully.\n",
            "[COMPLETE] ● Post-installation setup completed!\n",
            "[INIT].... → Running Crawl4AI health check...\n",
            "[INIT].... → Crawl4AI 0.4.247\n",
            "[TEST].... ℹ Testing crawling capabilities...\n",
            "[EXPORT].. ℹ Exporting PDF and taking screenshot took 3.16s\n",
            "[FETCH]... ↓ https://crawl4ai.com... | Status: True | Time: 5.48s\n",
            "[SCRAPE].. ◆ Processed https://crawl4ai.com... | Time: 124ms\n",
            "[COMPLETE] ● https://crawl4ai.com... | Status: True | Total: 5.60s\n",
            "[COMPLETE] ● ✅ Crawling test passed!\n",
            "Installing dependencies...\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "\n",
            "=== Sequential Crawling with Session Reuse ===\n",
            "[INIT].... → Crawl4AI 0.4.247\n",
            "[FETCH]... ↓ https://ai.pydantic.dev/agents/... | Status: True | Time: 2.50s\n",
            "[SCRAPE].. ◆ Processed https://ai.pydantic.dev/agents/... | Time: 223ms\n",
            "[COMPLETE] ● https://ai.pydantic.dev/agents/... | Status: True | Total: 2.82s\n",
            "Successfully crawled: https://ai.pydantic.dev/agents/\n",
            "Markdown length: 25064\n",
            "[FETCH]... ↓ https://ai.pydantic.dev/models/... | Status: True | Time: 2.18s\n",
            "[SCRAPE].. ◆ Processed https://ai.pydantic.dev/models/... | Time: 279ms\n",
            "[COMPLETE] ● https://ai.pydantic.dev/models/... | Status: True | Total: 2.53s\n",
            "Successfully crawled: https://ai.pydantic.dev/models/\n",
            "Markdown length: 34030\n",
            "[FETCH]... ↓ https://ai.pydantic.dev/dependencies/... | Status: True | Time: 3.62s\n",
            "[SCRAPE].. ◆ Processed https://ai.pydantic.dev/dependencies/... | Time: 588ms\n",
            "[COMPLETE] ● https://ai.pydantic.dev/dependencies/... | Status: True | Total: 4.26s\n",
            "Successfully crawled: https://ai.pydantic.dev/dependencies/\n",
            "Markdown length: 16235\n",
            "[FETCH]... ↓ https://ai.pydantic.dev/tools/... | Status: True | Time: 5.66s\n",
            "[SCRAPE].. ◆ Processed https://ai.pydantic.dev/tools/... | Time: 383ms\n",
            "[COMPLETE] ● https://ai.pydantic.dev/tools/... | Status: True | Total: 6.12s\n",
            "Successfully crawled: https://ai.pydantic.dev/tools/\n",
            "Markdown length: 19869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hUDO9qINOWO",
        "outputId": "84cbfbc1-8e6d-4fd8-f644-fd3d315ad8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/'Projetos Python - Google Colab (Colab Notebooks)'/Crawl4AI/Pydantic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-j8Gl9wWJ34",
        "outputId": "95f67d2f-2e23-44dc-f299-61a3709e699f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Crawl4AI\n",
            "'Pydantic AI  DeepSeek V3 - The BEST AI Agent Combo - English (auto-generated).txt'\n",
            " Transcriptions_saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/arquivos.zip /content/drive/MyDrive/pasta_com_seus_arquivos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p87C1qBJTnWB",
        "outputId": "d583a7e8-8a8c-4aeb-fef3-19500e5c6a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: /content/drive/MyDrive/pasta_com_seus_arquivos\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r /content/arquivos.zip . -i /content/drive/MyDrive/pasta_com_seus_arquivos)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My Drive/Projetos Python - Google Colab (Colab Notebooks)/Crawl4AI/Pydantic"
      ],
      "metadata": {
        "id": "_qdwiSzOUk-X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UkCJw-fSavwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# v2 - Modificação para baixar .md no diretório \"/content/drive/MyDrive/Projetos Python - Google Colab (Colab Notebooks)/Crawl4AI/Pydantic\""
      ],
      "metadata": {
        "id": "w9EpU6Saa4SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U crawl4ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQGAzDPaeK36",
        "outputId": "f42682a7-22f1-4724-98a2-d70092276a6b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crawl4ai in /usr/local/lib/python3.10/dist-packages (0.4.247)\n",
            "Requirement already satisfied: aiosqlite~=0.20 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.20.0)\n",
            "Requirement already satisfied: lxml~=5.3 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (5.3.0)\n",
            "Requirement already satisfied: litellm>=1.53.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.58.1)\n",
            "Requirement already satisfied: numpy<3,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.26.4)\n",
            "Requirement already satisfied: pillow~=10.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (10.4.0)\n",
            "Requirement already satisfied: playwright>=1.49.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.49.1)\n",
            "Requirement already satisfied: python-dotenv~=1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.0.1)\n",
            "Requirement already satisfied: requests~=2.26 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4~=4.12 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (4.12.3)\n",
            "Requirement already satisfied: tf-playwright-stealth>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.1.0)\n",
            "Requirement already satisfied: xxhash~=3.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.5.0)\n",
            "Requirement already satisfied: rank-bm25~=0.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.2.2)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (24.1.0)\n",
            "Requirement already satisfied: colorama~=0.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.4.6)\n",
            "Requirement already satisfied: snowballstemmer~=2.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.2.0)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.10.3)\n",
            "Requirement already satisfied: pyOpenSSL>=24.3.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (25.0.0)\n",
            "Requirement already satisfied: psutil>=6.1.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (6.1.1)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.9.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiosqlite~=0.20->crawl4ai) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.12->crawl4ai) (2.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.11.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.1.7)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.27.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.55.3 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (1.57.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.21.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (4.67.1)\n",
            "Requirement already satisfied: greenlet==3.1.1 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (3.1.1)\n",
            "Requirement already satisfied: pyee==12.0.0 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (12.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (2.27.1)\n",
            "Requirement already satisfied: cryptography<45,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL>=24.3.0->crawl4ai) (43.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2024.12.14)\n",
            "Requirement already satisfied: fake-http-header<0.4.0,>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.3.5)\n",
            "Requirement already satisfied: pytest-mockito<0.0.5,>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.22.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (0.8.2)\n",
            "Requirement already satisfied: pytest>=3 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (8.3.4)\n",
            "Requirement already satisfied: mockito>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.18.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm>=1.53.1->crawl4ai) (0.27.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (6.0.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependências\n",
        "!pip install -U crawl4ai\n",
        "!crawl4ai-setup\n",
        "!crawl4ai-doctor\n",
        "!python -m playwright install --with-deps chromium\n",
        "\n",
        "# Montar o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Importar bibliotecas\n",
        "import asyncio\n",
        "from typing import List\n",
        "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "\n",
        "# Definir o diretório de saída\n",
        "output_directory = \"/content/drive/MyDrive/Projetos Python - Google Colab (Colab Notebooks)/Crawl4AI/Pydantic\"\n",
        "\n",
        "# Função para rastreamento sequencial\n",
        "async def crawl_sequential(urls: List[str]):\n",
        "    print(\"\\n=== Sequential Crawling with Session Reuse ===\")\n",
        "\n",
        "    browser_config = BrowserConfig(\n",
        "        headless=True,\n",
        "        # For better performance in Docker or low-memory environments:\n",
        "        extra_args=[\"--disable-gpu\", \"--disable-dev-shm-usage\", \"--no-sandbox\"],\n",
        "    )\n",
        "\n",
        "    crawl_config = CrawlerRunConfig(\n",
        "        markdown_generator=DefaultMarkdownGenerator(),\n",
        "        output_dir=output_directory  # Configurar o diretório de saída aqui\n",
        "    )\n",
        "\n",
        "    # Criar o crawler (abre o navegador)\n",
        "    crawler = AsyncWebCrawler(config=browser_config)\n",
        "    await crawler.start()\n",
        "\n",
        "    try:\n",
        "        session_id = \"session1\"  # Reutilizar a mesma sessão em todas as URLs\n",
        "        for url in urls:\n",
        "            result = await crawler.arun(\n",
        "                url=url,\n",
        "                config=crawl_config,\n",
        "                session_id=session_id\n",
        "            )\n",
        "            if result.success:\n",
        "                print(f\"Successfully crawled: {url}\")\n",
        "                # Exemplo: verificar o tamanho do markdown\n",
        "                print(f\"Markdown length: {len(result.markdown_v2.raw_markdown)}\")\n",
        "            else:\n",
        "                print(f\"Failed: {url} - Error: {result.error_message}\")\n",
        "    finally:\n",
        "        # Depois que todas as URLs forem concluídas, fechar o crawler (e o navegador)\n",
        "        await crawler.close()\n",
        "\n",
        "# Função principal\n",
        "async def main():\n",
        "    urls = [\n",
        "        \"https://ai.pydantic.dev/agents/\",\n",
        "        \"https://ai.pydantic.dev/models/\",\n",
        "        \"https://ai.pydantic.dev/dependencies/\",\n",
        "        \"https://ai.pydantic.dev/tools/\"\n",
        "    ]\n",
        "    await crawl_sequential(urls)\n",
        "\n",
        "# Executar a função principal (usando await no Colab)\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qElxep7la3aY",
        "outputId": "5a2d5655-da55-463e-83ff-52dd49bdf4c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crawl4ai in /usr/local/lib/python3.10/dist-packages (0.4.247)\n",
            "Requirement already satisfied: aiosqlite~=0.20 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.20.0)\n",
            "Requirement already satisfied: lxml~=5.3 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (5.3.0)\n",
            "Requirement already satisfied: litellm>=1.53.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.58.1)\n",
            "Requirement already satisfied: numpy<3,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.26.4)\n",
            "Requirement already satisfied: pillow~=10.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (10.4.0)\n",
            "Requirement already satisfied: playwright>=1.49.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.49.1)\n",
            "Requirement already satisfied: python-dotenv~=1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.0.1)\n",
            "Requirement already satisfied: requests~=2.26 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4~=4.12 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (4.12.3)\n",
            "Requirement already satisfied: tf-playwright-stealth>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.1.0)\n",
            "Requirement already satisfied: xxhash~=3.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.5.0)\n",
            "Requirement already satisfied: rank-bm25~=0.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.2.2)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (24.1.0)\n",
            "Requirement already satisfied: colorama~=0.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.4.6)\n",
            "Requirement already satisfied: snowballstemmer~=2.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.2.0)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.10.3)\n",
            "Requirement already satisfied: pyOpenSSL>=24.3.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (25.0.0)\n",
            "Requirement already satisfied: psutil>=6.1.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (6.1.1)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.9.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiosqlite~=0.20->crawl4ai) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.12->crawl4ai) (2.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.11.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.1.7)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.27.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.55.3 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (1.57.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.21.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (4.67.1)\n",
            "Requirement already satisfied: greenlet==3.1.1 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (3.1.1)\n",
            "Requirement already satisfied: pyee==12.0.0 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (12.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (2.27.1)\n",
            "Requirement already satisfied: cryptography<45,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL>=24.3.0->crawl4ai) (43.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2024.12.14)\n",
            "Requirement already satisfied: fake-http-header<0.4.0,>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.3.5)\n",
            "Requirement already satisfied: pytest-mockito<0.0.5,>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.22.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (0.8.2)\n",
            "Requirement already satisfied: pytest>=3 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (8.3.4)\n",
            "Requirement already satisfied: mockito>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.18.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm>=1.53.1->crawl4ai) (0.27.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (6.0.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.2.1)\n",
            "[INIT].... → Running post-installation setup...\n",
            "[INIT].... → Installing Playwright browsers...\n",
            "Installing dependencies...\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "[COMPLETE] ● Playwright installation completed successfully.\n",
            "[INIT].... → Starting database initialization...\n",
            "[COMPLETE] ● Database initialization completed successfully.\n",
            "[COMPLETE] ● Post-installation setup completed!\n",
            "[INIT].... → Running Crawl4AI health check...\n",
            "[INIT].... → Crawl4AI 0.4.247\n",
            "[TEST].... ℹ Testing crawling capabilities...\n",
            "[EXPORT].. ℹ Exporting PDF and taking screenshot took 3.91s\n",
            "[FETCH]... ↓ https://crawl4ai.com... | Status: True | Time: 6.82s\n",
            "[SCRAPE].. ◆ Processed https://crawl4ai.com... | Time: 168ms\n",
            "[COMPLETE] ● https://crawl4ai.com... | Status: True | Total: 6.99s\n",
            "[COMPLETE] ● ✅ Crawling test passed!\n",
            "Installing dependencies...\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "=== Sequential Crawling with Session Reuse ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "CrawlerRunConfig.__init__() got an unexpected keyword argument 'output_dir'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b5abb05ae64a>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Executar a função principal (usando await no Colab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-b5abb05ae64a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;34m\"https://ai.pydantic.dev/tools/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     ]\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0;32mawait\u001b[0m \u001b[0mcrawl_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Executar a função principal (usando await no Colab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-b5abb05ae64a>\u001b[0m in \u001b[0;36mcrawl_sequential\u001b[0;34m(urls)\u001b[0m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     crawl_config = CrawlerRunConfig(\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mmarkdown_generator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDefaultMarkdownGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_directory\u001b[0m  \u001b[0;31m# Configurar o diretório de saída aqui\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: CrawlerRunConfig.__init__() got an unexpected keyword argument 'output_dir'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/Projetos Python - Google Colab (Colab Notebooks)/Crawl4AI/Pydantic\""
      ],
      "metadata": {
        "id": "PY1HnePkbHRp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependências\n",
        "!pip install -U crawl4ai\n",
        "!crawl4ai-setup\n",
        "!crawl4ai-doctor\n",
        "!python -m playwright install --with-deps chromium\n",
        "\n",
        "# Montar o Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Importar bibliotecas\n",
        "import asyncio\n",
        "from typing import List\n",
        "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "\n",
        "# Definir o diretório de saída\n",
        "output_directory = \"/content/drive/MyDrive/Projetos Python - Google Colab (Colab Notebooks)/Crawl4AI/Pydantic\"\n",
        "\n",
        "# Função para rastreamento sequencial (modificada)\n",
        "async def crawl_sequential(urls: List[str]):\n",
        "    print(\"\\n=== Sequential Crawling with Session Reuse ===\")\n",
        "\n",
        "    browser_config = BrowserConfig(\n",
        "        headless=True,\n",
        "        extra_args=[\"--disable-gpu\", \"--disable-dev-shm-usage\", \"--no-sandbox\"],\n",
        "    )\n",
        "\n",
        "    crawl_config = CrawlerRunConfig(\n",
        "        markdown_generator=DefaultMarkdownGenerator()\n",
        "        # Remova output_dir daqui\n",
        "    )\n",
        "\n",
        "    # Criar o crawler (abre o navegador)\n",
        "    crawler = AsyncWebCrawler(config=browser_config)\n",
        "    await crawler.start()\n",
        "\n",
        "    try:\n",
        "        session_id = \"session1\"  # Reutilizar a mesma sessão em todas as URLs\n",
        "        for url in urls:\n",
        "            result = await crawler.arun(\n",
        "                url=url,\n",
        "                config=crawl_config,\n",
        "                session_id=session_id\n",
        "            )\n",
        "            if result.success:\n",
        "                print(f\"Successfully crawled: {url}\")\n",
        "                print(f\"Markdown length: {len(result.markdown_v2.raw_markdown)}\")\n",
        "\n",
        "                # Salvar o arquivo manualmente\n",
        "                filename = os.path.join(output_directory, f\"{url.replace('/', '_')}.md\") # Nome do arquivo baseado na URL\n",
        "                os.makedirs(os.path.dirname(filename), exist_ok=True) # Cria o diretório se necessário\n",
        "                with open(filename, \"w\") as f:\n",
        "                    f.write(result.markdown_v2.raw_markdown)\n",
        "                print(f\"Markdown saved to: {filename}\")\n",
        "            else:\n",
        "                print(f\"Failed: {url} - Error: {result.error_message}\")\n",
        "    finally:\n",
        "        # Depois que todas as URLs forem concluídas, fechar o crawler (e o navegador)\n",
        "        await crawler.close()\n",
        "\n",
        "# Função principal\n",
        "async def main():\n",
        "    urls = [\n",
        "        \"https://ai.pydantic.dev/agents/\",\n",
        "        \"https://ai.pydantic.dev/models/\",\n",
        "        \"https://ai.pydantic.dev/dependencies/\",\n",
        "        \"https://ai.pydantic.dev/tools/\"\n",
        "    ]\n",
        "    await crawl_sequential(urls)\n",
        "\n",
        "# Executar a função principal (usando await no Colab)\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mN-Oqe1-fMDp",
        "outputId": "e13d4c01-5579-403d-f01e-2b08410890b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crawl4ai in /usr/local/lib/python3.10/dist-packages (0.4.247)\n",
            "Requirement already satisfied: aiosqlite~=0.20 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.20.0)\n",
            "Requirement already satisfied: lxml~=5.3 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (5.3.0)\n",
            "Requirement already satisfied: litellm>=1.53.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.58.1)\n",
            "Requirement already satisfied: numpy<3,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.26.4)\n",
            "Requirement already satisfied: pillow~=10.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (10.4.0)\n",
            "Requirement already satisfied: playwright>=1.49.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.49.1)\n",
            "Requirement already satisfied: python-dotenv~=1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.0.1)\n",
            "Requirement already satisfied: requests~=2.26 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4~=4.12 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (4.12.3)\n",
            "Requirement already satisfied: tf-playwright-stealth>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.1.0)\n",
            "Requirement already satisfied: xxhash~=3.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.5.0)\n",
            "Requirement already satisfied: rank-bm25~=0.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.2.2)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (24.1.0)\n",
            "Requirement already satisfied: colorama~=0.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.4.6)\n",
            "Requirement already satisfied: snowballstemmer~=2.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.2.0)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.10.3)\n",
            "Requirement already satisfied: pyOpenSSL>=24.3.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (25.0.0)\n",
            "Requirement already satisfied: psutil>=6.1.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (6.1.1)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.9.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiosqlite~=0.20->crawl4ai) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.12->crawl4ai) (2.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.11.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.1.7)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.27.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.55.3 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (1.57.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.21.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (4.67.1)\n",
            "Requirement already satisfied: greenlet==3.1.1 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (3.1.1)\n",
            "Requirement already satisfied: pyee==12.0.0 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (12.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (2.27.1)\n",
            "Requirement already satisfied: cryptography<45,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL>=24.3.0->crawl4ai) (43.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2024.12.14)\n",
            "Requirement already satisfied: fake-http-header<0.4.0,>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.3.5)\n",
            "Requirement already satisfied: pytest-mockito<0.0.5,>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.22.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (0.8.2)\n",
            "Requirement already satisfied: pytest>=3 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (8.3.4)\n",
            "Requirement already satisfied: mockito>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.18.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm>=1.53.1->crawl4ai) (0.27.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (6.0.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.2.1)\n",
            "[INIT].... → Running post-installation setup...\n",
            "[INIT].... → Installing Playwright browsers...\n",
            "Installing dependencies...\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "[COMPLETE] ● Playwright installation completed successfully.\n",
            "[INIT].... → Starting database initialization...\n",
            "[COMPLETE] ● Database initialization completed successfully.\n",
            "[COMPLETE] ● Post-installation setup completed!\n",
            "[INIT].... → Running Crawl4AI health check...\n",
            "[INIT].... → Crawl4AI 0.4.247\n",
            "[TEST].... ℹ Testing crawling capabilities...\n",
            "[EXPORT].. ℹ Exporting PDF and taking screenshot took 2.30s\n",
            "[FETCH]... ↓ https://crawl4ai.com... | Status: True | Time: 4.35s\n",
            "[SCRAPE].. ◆ Processed https://crawl4ai.com... | Time: 131ms\n",
            "[COMPLETE] ● https://crawl4ai.com... | Status: True | Total: 4.49s\n",
            "[COMPLETE] ● ✅ Crawling test passed!\n",
            "Installing dependencies...\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "=== Sequential Crawling with Session Reuse ===\n",
            "[INIT].... → Crawl4AI 0.4.247\n",
            "[FETCH]... ↓ https://ai.pydantic.dev/agents/... | Status: True | Time: 0.07s\n",
            "[COMPLETE] ● https://ai.pydantic.dev/agents/... | Status: True | Total: 0.13s\n",
            "Successfully crawled: https://ai.pydantic.dev/agents/\n",
            "Markdown length: 25064\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-56134ae4dbdc>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Executar a função principal (usando await no Colab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-56134ae4dbdc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;34m\"https://ai.pydantic.dev/tools/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     ]\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mawait\u001b[0m \u001b[0mcrawl_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Executar a função principal (usando await no Colab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-56134ae4dbdc>\u001b[0m in \u001b[0;36mcrawl_sequential\u001b[0;34m(urls)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# Salvar o arquivo manualmente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{url.replace('/', '_')}.md\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Nome do arquivo baseado na URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Cria o diretório se necessário\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V3 - 🔥 Faz o Crawler e baixa diretamente no Desktop 🔥\n",
        "OBS.: Eu estava colocando pra salvar no Drive mas a a versão do crawl4ai (0.4.247) que você está usando não suporta o argumento output_dir no construtor CrawlerRunConfig.\n",
        "\n",
        "**Explicações:**\n",
        "\n",
        "1. **`temp_output_directory = \"/content/crawl4ai_temp_output\"`:** Define um diretório temporário dentro do ambiente do Colab para armazenar os arquivos Markdown.\n",
        "2. **`crawl_sequential` (modificada):**\n",
        "    *   O `output_dir` foi removido do `CrawlerRunConfig`.\n",
        "    *   Os arquivos são salvos temporariamente no `temp_output_directory` usando a lógica que discutimos anteriormente (`os.makedirs`, `with open...`).\n",
        "3. **`shutil.make_archive(\"crawl4ai_output\", 'zip', temp_output_directory)`:**\n",
        "    *   Após o rastreamento, esta linha usa a função `make_archive` do módulo `shutil` para compactar o diretório temporário em um arquivo chamado `crawl4ai_output.zip`.\n",
        "4. **`files.download(\"crawl4ai_output.zip\")`:** Esta linha usa a função `download` do `google.colab.files` para disponibilizar o arquivo zipado para download no seu navegador.\n",
        "\n",
        "**Como executar:**\n",
        "\n",
        "1. Execute o código.\n",
        "2. O código irá rastrear as URLs e salvar os arquivos Markdown temporariamente.\n",
        "3. Ao final da execução, o arquivo `crawl4ai_output.zip` será baixado automaticamente pelo seu navegador.\n",
        "4. Descompacte o arquivo `.zip` para acessar os arquivos Markdown.\n",
        "\n",
        "**Limpeza (opcional):**\n",
        "\n",
        "*   Você pode adicionar o seguinte código ao final da função `main()` para remover o diretório temporário após o download, se desejar:\n",
        "\n",
        "```python\n",
        "shutil.rmtree(temp_output_directory)\n",
        "print(f\"Temporary output directory removed: {temp_output_directory}\")\n",
        "```\n",
        "\n",
        "Esta solução alternativa permite que você baixe os arquivos gerados pelo `crawl4ai` como um arquivo zipado, mesmo que esteja enfrentando problemas com o argumento `output_dir`.\n"
      ],
      "metadata": {
        "id": "RmB4YkEohVw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependências\n",
        "!pip install -U crawl4ai\n",
        "!crawl4ai-setup\n",
        "!crawl4ai-doctor\n",
        "!python -m playwright install --with-deps chromium\n",
        "\n",
        "# Importar bibliotecas\n",
        "import asyncio\n",
        "from typing import List\n",
        "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Definir o diretório temporário para salvar os arquivos\n",
        "temp_output_directory = \"/content/crawl4ai_temp_output\"\n",
        "\n",
        "# Função para rastreamento sequencial\n",
        "async def crawl_sequential(urls: List[str]):\n",
        "    print(\"\\n=== Sequential Crawling with Session Reuse ===\")\n",
        "\n",
        "    browser_config = BrowserConfig(\n",
        "        headless=True,\n",
        "        extra_args=[\"--disable-gpu\", \"--disable-dev-shm-usage\", \"--no-sandbox\"],\n",
        "    )\n",
        "\n",
        "    crawl_config = CrawlerRunConfig(\n",
        "        markdown_generator=DefaultMarkdownGenerator()\n",
        "        # Sem output_dir\n",
        "    )\n",
        "\n",
        "    # Criar o crawler (abre o navegador)\n",
        "    crawler = AsyncWebCrawler(config=browser_config)\n",
        "    await crawler.start()\n",
        "\n",
        "    try:\n",
        "        session_id = \"session1\"  # Reutilizar a mesma sessão em todas as URLs\n",
        "        for url in urls:\n",
        "            result = await crawler.arun(\n",
        "                url=url,\n",
        "                config=crawl_config,\n",
        "                session_id=session_id\n",
        "            )\n",
        "            if result.success:\n",
        "                print(f\"Successfully crawled: {url}\")\n",
        "                print(f\"Markdown length: {len(result.markdown_v2.raw_markdown)}\")\n",
        "\n",
        "                # Salvar o arquivo temporariamente\n",
        "                filename = os.path.join(temp_output_directory, f\"{url.replace('/', '_')}.md\")\n",
        "                os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "                with open(filename, \"w\") as f:\n",
        "                    f.write(result.markdown_v2.raw_markdown)\n",
        "                print(f\"Markdown saved to: {filename}\")\n",
        "\n",
        "            else:\n",
        "                print(f\"Failed: {url} - Error: {result.error_message}\")\n",
        "    finally:\n",
        "        # Depois que todas as URLs forem concluídas, fechar o crawler (e o navegador)\n",
        "        await crawler.close()\n",
        "\n",
        "# Função principal - ⚠️INSIRA AQUI AS URLs para Crawler⚠️\n",
        "async def main():\n",
        "    urls = [\n",
        "        \"https://ai.pydantic.dev/agents/\",\n",
        "        \"https://ai.pydantic.dev/models/\",\n",
        "        \"https://ai.pydantic.dev/dependencies/\",\n",
        "        \"https://ai.pydantic.dev/tools/\"\n",
        "    ]\n",
        "    await crawl_sequential(urls)\n",
        "\n",
        "    # Compactar a pasta de saída\n",
        "    shutil.make_archive(\"crawl4ai_output\", 'zip', temp_output_directory)\n",
        "    print(f\"Output directory zipped to crawl4ai_output.zip\")\n",
        "\n",
        "    # Disponibilizar para download\n",
        "    files.download(\"crawl4ai_output.zip\")\n",
        "\n",
        "# Executar a função principal\n",
        "await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BaZLOsp0hWrh",
        "outputId": "abfe38c0-03dd-4459-b3b7-1f8b37681612"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: crawl4ai in /usr/local/lib/python3.10/dist-packages (0.4.247)\n",
            "Requirement already satisfied: aiosqlite~=0.20 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.20.0)\n",
            "Requirement already satisfied: lxml~=5.3 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (5.3.0)\n",
            "Requirement already satisfied: litellm>=1.53.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.58.1)\n",
            "Requirement already satisfied: numpy<3,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.26.4)\n",
            "Requirement already satisfied: pillow~=10.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (10.4.0)\n",
            "Requirement already satisfied: playwright>=1.49.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.49.1)\n",
            "Requirement already satisfied: python-dotenv~=1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.0.1)\n",
            "Requirement already satisfied: requests~=2.26 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4~=4.12 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (4.12.3)\n",
            "Requirement already satisfied: tf-playwright-stealth>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (1.1.0)\n",
            "Requirement already satisfied: xxhash~=3.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.5.0)\n",
            "Requirement already satisfied: rank-bm25~=0.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.2.2)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (24.1.0)\n",
            "Requirement already satisfied: colorama~=0.4 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (0.4.6)\n",
            "Requirement already satisfied: snowballstemmer~=2.2 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.2.0)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (2.10.3)\n",
            "Requirement already satisfied: pyOpenSSL>=24.3.0 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (25.0.0)\n",
            "Requirement already satisfied: psutil>=6.1.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (6.1.1)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from crawl4ai) (3.9.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiosqlite~=0.20->crawl4ai) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.12->crawl4ai) (2.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.11.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.1.7)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.27.2)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (3.1.4)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (4.23.0)\n",
            "Requirement already satisfied: openai>=1.55.3 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (1.57.4)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.8.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (from litellm>=1.53.1->crawl4ai) (0.21.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.9.1->crawl4ai) (4.67.1)\n",
            "Requirement already satisfied: greenlet==3.1.1 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (3.1.1)\n",
            "Requirement already satisfied: pyee==12.0.0 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.49.0->crawl4ai) (12.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.10->crawl4ai) (2.27.1)\n",
            "Requirement already satisfied: cryptography<45,>=41.0.5 in /usr/local/lib/python3.10/dist-packages (from pyOpenSSL>=24.3.0->crawl4ai) (43.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.26->crawl4ai) (2024.12.14)\n",
            "Requirement already satisfied: fake-http-header<0.4.0,>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.3.5)\n",
            "Requirement already satisfied: pytest-mockito<0.0.5,>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.22.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.55.3->litellm>=1.53.1->crawl4ai) (0.8.2)\n",
            "Requirement already satisfied: pytest>=3 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (8.3.4)\n",
            "Requirement already satisfied: mockito>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->litellm>=1.53.1->crawl4ai) (1.18.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers->litellm>=1.53.1->crawl4ai) (0.27.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.23.0->litellm>=1.53.1->crawl4ai) (1.2.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<45,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (6.0.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest>=3->pytest-mockito<0.0.5,>=0.0.4->tf-playwright-stealth>=1.1.0->crawl4ai) (2.2.1)\n",
            "[INIT].... → Running post-installation setup...\n",
            "[INIT].... → Installing Playwright browsers...\n",
            "Installing dependencies...\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "[COMPLETE] ● Playwright installation completed successfully.\n",
            "[INIT].... → Starting database initialization...\n",
            "[COMPLETE] ● Database initialization completed successfully.\n",
            "[COMPLETE] ● Post-installation setup completed!\n",
            "[INIT].... → Running Crawl4AI health check...\n",
            "[INIT].... → Crawl4AI 0.4.247\n",
            "[TEST].... ℹ Testing crawling capabilities...\n",
            "[EXPORT].. ℹ Exporting PDF and taking screenshot took 1.99s\n",
            "[FETCH]... ↓ https://crawl4ai.com... | Status: True | Time: 4.42s\n",
            "[SCRAPE].. ◆ Processed https://crawl4ai.com... | Time: 115ms\n",
            "[COMPLETE] ● https://crawl4ai.com... | Status: True | Total: 4.53s\n",
            "[COMPLETE] ● ✅ Crawling test passed!\n",
            "Installing dependencies...\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.042-0ubuntu0.22.04.1).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.4).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 62 not upgraded.\n",
            "\n",
            "=== Sequential Crawling with Session Reuse ===\n",
            "[INIT].... → Crawl4AI 0.4.247\n",
            "[FETCH]... ↓ https://ai.pydantic.dev/agents/... | Status: True | Time: 0.01s\n",
            "[COMPLETE] ● https://ai.pydantic.dev/agents/... | Status: True | Total: 0.02s\n",
            "Successfully crawled: https://ai.pydantic.dev/agents/\n",
            "Markdown length: 25064\n",
            "Markdown saved to: /content/crawl4ai_temp_output/https:__ai.pydantic.dev_agents_.md\n",
            "[FETCH]... ↓ https://ai.pydantic.dev/models/... | Status: True | Time: 0.03s\n",
            "[COMPLETE] ● https://ai.pydantic.dev/models/... | Status: True | Total: 0.04s\n",
            "Successfully crawled: https://ai.pydantic.dev/models/\n",
            "Markdown length: 34030\n",
            "Markdown saved to: /content/crawl4ai_temp_output/https:__ai.pydantic.dev_models_.md\n",
            "[FETCH]... ↓ https://ai.pydantic.dev/dependencies/... | Status: True | Time: 0.10s\n",
            "[COMPLETE] ● https://ai.pydantic.dev/dependencies/... | Status: True | Total: 0.17s\n",
            "Successfully crawled: https://ai.pydantic.dev/dependencies/\n",
            "Markdown length: 16235\n",
            "Markdown saved to: /content/crawl4ai_temp_output/https:__ai.pydantic.dev_dependencies_.md\n",
            "[FETCH]... ↓ https://ai.pydantic.dev/tools/... | Status: True | Time: 0.02s\n",
            "[COMPLETE] ● https://ai.pydantic.dev/tools/... | Status: True | Total: 0.03s\n",
            "Successfully crawled: https://ai.pydantic.dev/tools/\n",
            "Markdown length: 19869\n",
            "Markdown saved to: /content/crawl4ai_temp_output/https:__ai.pydantic.dev_tools_.md\n",
            "Output directory zipped to crawl4ai_output.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9f009cb6-e64a-46a1-9883-931a2ca92817\", \"crawl4ai_output.zip\", 21556)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V3.1 - 🔥 Faz o Crawler e baixa diretamente no Desktop 🔥 (COM SEPARAÇÃO DE CÉLULAS)\n",
        "OBS.: Eu estava colocando pra salvar no Drive mas a a versão do crawl4ai (0.4.247) que você está usando não suporta o argumento output_dir no construtor CrawlerRunConfig.\n",
        "\n",
        "**Explicações:**\n",
        "\n",
        "1. **`temp_output_directory = \"/content/crawl4ai_temp_output\"`:** Define um diretório temporário dentro do ambiente do Colab para armazenar os arquivos Markdown.\n",
        "2. **`crawl_sequential` (modificada):**\n",
        "    *   O `output_dir` foi removido do `CrawlerRunConfig`.\n",
        "    *   Os arquivos são salvos temporariamente no `temp_output_directory` usando a lógica que discutimos anteriormente (`os.makedirs`, `with open...`).\n",
        "3. **`shutil.make_archive(\"crawl4ai_output\", 'zip', temp_output_directory)`:**\n",
        "    *   Após o rastreamento, esta linha usa a função `make_archive` do módulo `shutil` para compactar o diretório temporário em um arquivo chamado `crawl4ai_output.zip`.\n",
        "4. **`files.download(\"crawl4ai_output.zip\")`:** Esta linha usa a função `download` do `google.colab.files` para disponibilizar o arquivo zipado para download no seu navegador.\n",
        "\n",
        "**Como executar:**\n",
        "\n",
        "1. Execute o código.\n",
        "2. O código irá rastrear as URLs e salvar os arquivos Markdown temporariamente.\n",
        "3. Ao final da execução, o arquivo `crawl4ai_output.zip` será baixado automaticamente pelo seu navegador.\n",
        "4. Descompacte o arquivo `.zip` para acessar os arquivos Markdown.\n",
        "\n",
        "📌**Fluxo de trabalho recomendado:** (📌NOVIDADE v3.1📌)\n",
        "\n",
        "1. **Execute a célula de dependências uma vez** no início ou sempre que precisar instalar ou atualizar uma biblioteca.\n",
        "2. **Reinicie o ambiente de execução (Runtime -> Restart runtime)** após instalar as dependências (especialmente se você atualizou uma biblioteca). Isso garante que as novas versões das bibliotecas sejam carregadas corretamente.\n",
        "3. **Execute as células de código principal** sempre que fizer alterações no código e precisar testá-las. Você não precisa executar a célula de dependências novamente, a menos que precise alterar as bibliotecas instaladas.\n",
        "\n",
        "**Limpeza (opcional):**\n",
        "\n",
        "*   Você pode adicionar o seguinte código ao final da função `main()` para remover o diretório temporário após o download, se desejar:\n",
        "\n",
        "```python\n",
        "shutil.rmtree(temp_output_directory)\n",
        "print(f\"Temporary output directory removed: {temp_output_directory}\")\n",
        "```\n",
        "\n",
        "Esta solução alternativa permite que você baixe os arquivos gerados pelo `crawl4ai` como um arquivo zipado, mesmo que esteja enfrentando problemas com o argumento `output_dir`.\n"
      ],
      "metadata": {
        "id": "eFAKNjlhj-Yp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Célula de dependências:"
      ],
      "metadata": {
        "id": "QHKIw3n3kKUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar dependências (execute esta célula apenas uma vez ou quando precisar atualizar as bibliotecas)\n",
        "!pip install -U crawl4ai\n",
        "!crawl4ai-setup\n",
        "!crawl4ai-doctor\n",
        "!python -m playwright install --with-deps chromium"
      ],
      "metadata": {
        "id": "GzghpzHLkIDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Células de código principal:"
      ],
      "metadata": {
        "id": "_SFuoJMXkO2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas (execute esta célula sempre que reiniciar o ambiente de execução)\n",
        "import asyncio\n",
        "from typing import List\n",
        "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Definir o diretório temporário para salvar os arquivos\n",
        "temp_output_directory = \"/content/crawl4ai_temp_output\"\n",
        "\n",
        "# ... (o restante do seu código)"
      ],
      "metadata": {
        "id": "wTGWYzcDkVIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Fluxo de trabalho recomendado:"
      ],
      "metadata": {
        "id": "zwMavkwvkRk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para rastreamento sequencial\n",
        "async def crawl_sequential(urls: List[str]):\n",
        "    print(\"\\n=== Sequential Crawling with Session Reuse ===\")\n",
        "\n",
        "    browser_config = BrowserConfig(\n",
        "        headless=True,\n",
        "        extra_args=[\"--disable-gpu\", \"--disable-dev-shm-usage\", \"--no-sandbox\"],\n",
        "    )\n",
        "\n",
        "    crawl_config = CrawlerRunConfig(\n",
        "        markdown_generator=DefaultMarkdownGenerator()\n",
        "        # Sem output_dir\n",
        "    )\n",
        "\n",
        "    # Criar o crawler (abre o navegador)\n",
        "    crawler = AsyncWebCrawler(config=browser_config)\n",
        "    await crawler.start()\n",
        "\n",
        "    try:\n",
        "        session_id = \"session1\"  # Reutilizar a mesma sessão em todas as URLs\n",
        "        for url in urls:\n",
        "            result = await crawler.arun(\n",
        "                url=url,\n",
        "                config=crawl_config,\n",
        "                session_id=session_id\n",
        "            )\n",
        "            if result.success:\n",
        "                print(f\"Successfully crawled: {url}\")\n",
        "                print(f\"Markdown length: {len(result.markdown_v2.raw_markdown)}\")\n",
        "\n",
        "                # Salvar o arquivo temporariamente\n",
        "                filename = os.path.join(temp_output_directory, f\"{url.replace('/', '_')}.md\")\n",
        "                os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "                with open(filename, \"w\") as f:\n",
        "                    f.write(result.markdown_v2.raw_markdown)\n",
        "                print(f\"Markdown saved to: {filename}\")\n",
        "\n",
        "            else:\n",
        "                print(f\"Failed: {url} - Error: {result.error_message}\")\n",
        "    finally:\n",
        "        # Depois que todas as URLs forem concluídas, fechar o crawler (e o navegador)\n",
        "        await crawler.close()\n",
        "\n",
        "# Função principal - ⚠️INSIRA AQUI AS URLs para Crawler⚠️\n",
        "async def main():\n",
        "    urls = [\n",
        "        \"https://ai.pydantic.dev/agents/\",\n",
        "        \"https://ai.pydantic.dev/models/\",\n",
        "        \"https://ai.pydantic.dev/dependencies/\",\n",
        "        \"https://ai.pydantic.dev/tools/\"\n",
        "    ]\n",
        "    await crawl_sequential(urls)\n",
        "\n",
        "    # Compactar a pasta de saída\n",
        "    shutil.make_archive(\"crawl4ai_output\", 'zip', temp_output_directory)\n",
        "    print(f\"Output directory zipped to crawl4ai_output.zip\")\n",
        "\n",
        "    # Disponibilizar para download\n",
        "    files.download(\"crawl4ai_output.zip\")\n",
        "\n",
        "# Executar a função principal\n",
        "await main()"
      ],
      "metadata": {
        "id": "2MtTZyC1kVjC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}